{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns to a specific csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import config as cfg\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "filename = 'nsmallest_fee_0.2% - 01-07-2023'\n",
    "df = pd.read_csv(f'../outputs/{filename}.csv')\n",
    "\n",
    "df['fee_%'] = 0.2\n",
    "df['num_tickers'] = 208\n",
    "df['nsmallest/nlargest'] = 'nsmallest'\n",
    "\n",
    "df.to_csv(f'../outputs/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "filename = 'combined_profit_results'\n",
    "df = pd.read_csv(f'../outputs/{filename}.csv')\n",
    "\n",
    "df['parameters'] = 0.2\n",
    "df['num_tickers'] = 208\n",
    "df['nsmallest/nlargest'] = 'nsmallest'\n",
    "\n",
    "df.to_csv(f'../outputs/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../outputs/combined_profit_results.csv')\n",
    "\n",
    "# Create the \"parameters\" column by concatenating other columns\n",
    "df['parameters'] = 'w' + df['watch_days'].astype(str) + ', h' + df['hold_days'].astype(str) + ', n' + df['num_stocks_to_buy'].astype(str) + ', l' + df['loss_limit'].astype(str) + ', f' + df['fee_%'].astype(str) + ', nt' + df['num_tickers'].astype(str) + ', ' + df['nsmallest/nlargest'].astype(str)\n",
    "\n",
    "# Reorder the columns to place the \"parameters\" column in the third position\n",
    "columns = list(df.columns)\n",
    "columns.insert(2, 'parameters')\n",
    "df = df.reindex(columns=columns)\n",
    "\n",
    "df.to_csv(f'../outputs/combined_profit_results2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns in all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = '../outputs/'\n",
    "\n",
    "# Define the columns and their desired new positions\n",
    "column_positions = {\n",
    "    'fee_%': 5,  # Zero-based index for the 5th column\n",
    "    'num_tickers': 6,  # Zero-based index for the 6th column\n",
    "    'nsmallest/nlargest': 7  # Zero-based index for the 7th column\n",
    "}\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read each CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Iterate over the columns and their new positions\n",
    "        for column_name, new_index in column_positions.items():\n",
    "            # Get the index of the column to be moved\n",
    "            current_index = df.columns.get_loc(column_name)\n",
    "\n",
    "            # Remove the column from its current position\n",
    "            column = df.pop(column_name)\n",
    "\n",
    "            # Insert the column at the desired position\n",
    "            df.insert(new_index, column_name, column)\n",
    "\n",
    "        # Save the updated DataFrame to the same CSV file, overwriting the original file\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move column year to 2nd column position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../outputs/combined_profit_results.csv')\n",
    "\n",
    "# Get the index of the \"year\" column\n",
    "current_index = df.columns.get_loc(\"year\")\n",
    "\n",
    "# Remove the \"year\" column from its current position\n",
    "column = df.pop(\"year\")\n",
    "\n",
    "# Insert the \"year\" column at the desired position (index 1)\n",
    "df.insert(1, \"year\", column)\n",
    "\n",
    "df.to_csv('../outputs/combined_profit_results_2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all csv files and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = '../outputs/'\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read each CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the combined DataFrame\n",
    "        combined_df = combined_df.append(df, ignore_index=True)\n",
    "\n",
    "# Drop duplicate rows from the combined DataFrame\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort the DataFrame by \"yearly_profit\" column in descending order\n",
    "combined_df.sort_values('yearly_profit', ascending=False, inplace=True)\n",
    "\n",
    "print(len(combined_df))\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(f'{folder_path}combined_profit_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SpecificationError",
     "evalue": "nested renamer is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpecificationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexis/code/stock/utils/reformat_results.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../outputs/combined_profit_results.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pivot_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mpivot_table(df,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                              index\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mwatch_days\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mhold_days\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnum_stocks_to_buy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mloss_limit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfee_\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnum_tickers\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnsmallest/nlargest\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                              columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                              values\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39myearly_profit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwin_ratio\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                              aggfunc\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39myearly_profit\u001b[39;49m\u001b[39m'\u001b[39;49m: {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                     \u001b[39m'\u001b[39;49m\u001b[39mmedian_profit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                     \u001b[39m'\u001b[39;49m\u001b[39mmean_profit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                                     \u001b[39m'\u001b[39;49m\u001b[39mmin_profit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                     \u001b[39m'\u001b[39;49m\u001b[39mmax_profit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                 },\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mwin_ratio\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                              },\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                              margins\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# pivot_table = pivot_table.sort_values(by=[('yearly_profit', 'median')], ascending=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexis/code/stock/utils/reformat_results.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(pivot_table\u001b[39m.\u001b[39mto_markdown())\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:95\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     92\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[1;32m     96\u001b[0m     data,\n\u001b[1;32m     97\u001b[0m     values,\n\u001b[1;32m     98\u001b[0m     index,\n\u001b[1;32m     99\u001b[0m     columns,\n\u001b[1;32m    100\u001b[0m     aggfunc,\n\u001b[1;32m    101\u001b[0m     fill_value,\n\u001b[1;32m    102\u001b[0m     margins,\n\u001b[1;32m    103\u001b[0m     dropna,\n\u001b[1;32m    104\u001b[0m     margins_name,\n\u001b[1;32m    105\u001b[0m     observed,\n\u001b[1;32m    106\u001b[0m     sort,\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:165\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    162\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(values)\n\u001b[1;32m    164\u001b[0m grouped \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mgroupby(keys, observed\u001b[39m=\u001b[39mobserved, sort\u001b[39m=\u001b[39msort)\n\u001b[0;32m--> 165\u001b[0m agged \u001b[39m=\u001b[39m grouped\u001b[39m.\u001b[39;49magg(aggfunc)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m dropna \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(agged, ABCDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(agged\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m    167\u001b[0m     agged \u001b[39m=\u001b[39m agged\u001b[39m.\u001b[39mdropna(how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/groupby/generic.py:869\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    868\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 869\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py:168\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    170\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py:467\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m     selected_obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selected_obj\n\u001b[1;32m    465\u001b[0m     selection \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selection\n\u001b[0;32m--> 467\u001b[0m arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m, selected_obj, arg)\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     colg \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_gotitem(selection, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py:578\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[39m# Can't use func.values(); wouldn't work for a Series\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    573\u001b[0m     how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39magg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ABCSeries)\n\u001b[1;32m    575\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(is_list_like(v) \u001b[39mfor\u001b[39;00m _, v \u001b[39min\u001b[39;00m func\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    576\u001b[0m ) \u001b[39mor\u001b[39;00m (\u001b[39many\u001b[39m(is_dict_like(v) \u001b[39mfor\u001b[39;00m _, v \u001b[39min\u001b[39;00m func\u001b[39m.\u001b[39mitems())):\n\u001b[1;32m    577\u001b[0m     \u001b[39m# GH 15931 - deprecation of renaming keys\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mraise\u001b[39;00m SpecificationError(\u001b[39m\"\u001b[39m\u001b[39mnested renamer is not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    581\u001b[0m     \u001b[39m# Check for missing columns on a frame\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     cols \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(func\u001b[39m.\u001b[39mkeys()) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(obj\u001b[39m.\u001b[39mcolumns)\n",
      "\u001b[0;31mSpecificationError\u001b[0m: nested renamer is not supported"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../outputs/combined_profit_results.csv')\n",
    "\n",
    "pivot_table = pd.pivot_table(df,\n",
    "                             index=['watch_days', 'hold_days', 'num_stocks_to_buy', 'loss_limit', 'fee_%', 'num_tickers', 'nsmallest/nlargest'],\n",
    "                             columns='year',\n",
    "                             values=['yearly_profit', 'win_ratio'],\n",
    "                             aggfunc={\n",
    "                                'yearly_profit': ['median', 'mean', 'min', 'max'],\n",
    "                                'win_ratio': 'median'\n",
    "                             },\n",
    "                             margins=True)\n",
    "\n",
    "# Rename the columns to include the aggregation function names\n",
    "pivot_table.columns = ['_'.join(col) for col in pivot_table.columns]\n",
    "\n",
    "\n",
    "# pivot_table = pivot_table.sort_values(by=[('yearly_profit', 'median')], ascending=False)\n",
    "\n",
    "print(pivot_table.to_markdown())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../outputs/combined_profit_results.csv')\n",
    "\n",
    "# Add a new column with the first 4 characters of the \"date_range\" column\n",
    "df['year'] = df['date_range'].str[:4]\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df.head(10))\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df.to_csv('../outputs/combined_profit_results_year.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
