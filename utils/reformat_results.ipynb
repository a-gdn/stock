{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder columns in all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = '../outputs/aa/'\n",
    "\n",
    "# Define the columns and their desired new positions\n",
    "column_positions = {\n",
    "    # 'fee_%': 5,  # Zero-based index for the 5th column\n",
    "    # 'num_tickers': 6,  # Zero-based index for the 6th column\n",
    "    'nlargest_nsmallest': 7  # Zero-based index for the 7th column\n",
    "}\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read each CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Iterate over the columns and their new positions\n",
    "        for column_name, new_index in column_positions.items():\n",
    "            # Get the index of the column to be moved\n",
    "            current_index = df.columns.get_loc(column_name)\n",
    "\n",
    "            # Remove the column from its current position\n",
    "            column = df.pop(column_name)\n",
    "\n",
    "            # Insert the column at the desired position\n",
    "            df.insert(new_index, column_name, column)\n",
    "\n",
    "        # Save the updated DataFrame to the same CSV file, overwriting the original file\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all csv files and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = '../outputs/aa/'\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read each CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the combined DataFrame\n",
    "        combined_df = combined_df.append(df, ignore_index=True)\n",
    "\n",
    "# Drop duplicate rows from the combined DataFrame\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort the DataFrame by \"yearly_profit\" column in descending order\n",
    "combined_df.sort_values('yearly_profit', ascending=False, inplace=True)\n",
    "\n",
    "print(len(combined_df))\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(f'{folder_path}2023-07-11_combined_profit_results2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'results_2023-07-29_17h30m24s'\n",
    "\n",
    "df = pd.read_csv(f'../outputs/{filename}.csv')\n",
    "\n",
    "# Add column year & move to 2nd column\n",
    "df['year'] = df['date_range'].str[:4]\n",
    "# current_index = df.columns.get_loc(\"year\") # Get the index of the \"year\" column\n",
    "column = df.pop(\"year\") # Remove the \"year\" column from its current position\n",
    "df.insert(1, \"year\", column) # Insert the \"year\" column at the desired position (index 1)\n",
    "\n",
    "df.to_csv(f'../outputs/{filename}.csv', index=False)\n",
    "\n",
    "# pivot_table = pd.pivot_table(df,\n",
    "#                              index=['watch_days', 'hold_days', 'num_stocks_to_buy', 'loss_limit', 'fee_%', 'num_tickers', 'nsmallest/nlargest'],\n",
    "#                              columns=['year'],\n",
    "#                              values=['yearly_profit', 'win_ratio'],\n",
    "#                              aggfunc={\n",
    "#                                 'yearly_profit': ['median', 'mean', 'min', 'max', ('count where < 1', lambda x: (x < 1).sum()), 'count'],\n",
    "#                                 'win_ratio': [('win_median', lambda x: np.median(x))]\n",
    "#                              },\n",
    "#                              margins=True)\n",
    "\n",
    "def get_overall_cross_tab(df):\n",
    "    def get_cross_tab(df, values_column, agg_funcs, sorting_func):\n",
    "        cross_tab = pd.crosstab(\n",
    "            index=[df['start_watch_time'], df['buy_time'], df['sell_time'], df['rank'], df['pct_change_threshold'], df['watch_days'], df['hold_days'], df['num_stocks_to_buy'], df['loss_limit'], df['fee'], df['num_tickers']],\n",
    "            columns=df['year'],\n",
    "            values=df[values_column],\n",
    "            aggfunc=agg_funcs,\n",
    "            margins=True)\n",
    "\n",
    "        cross_tab = cross_tab.sort_values(by=[(sorting_func, 'All')], ascending=False)\n",
    "\n",
    "        return cross_tab\n",
    "\n",
    "    cross_tab_profit = get_cross_tab(df, 'yearly_profit', ['median', 'mean', 'min', 'max', 'count'], 'median')\n",
    "    cross_tab_win_ratio = get_cross_tab(df, 'win_ratio', ['mean'], 'mean')\n",
    "\n",
    "    cross_tab_profit.columns = pd.MultiIndex.from_tuples([('yearly_profit', col) for col in cross_tab_profit.columns])\n",
    "    cross_tab_win_ratio.columns = pd.MultiIndex.from_tuples([('win_ratio', col) for col in cross_tab_win_ratio.columns])\n",
    "\n",
    "    overall_cross_tab = pd.concat([cross_tab_profit, cross_tab_win_ratio], axis=1)\n",
    "\n",
    "    print(overall_cross_tab.to_markdown())\n",
    "\n",
    "\n",
    "    return overall_cross_tab\n",
    "\n",
    "overall_cross_tab = get_overall_cross_tab(df)\n",
    "\n",
    "overall_cross_tab.to_csv(f'../outputs/pivot_table_{filename}.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert single column CSV file to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACKB.BR', 'AED.BR', 'AGS.BR', 'ARGX.BR', 'AZE.BR', 'BEKB.BR', 'COFB.BR', 'COLR.BR', 'DIE.BR', 'ELI.BR', 'EURN.BR', 'FAGR.BR', 'GBLB.BR', 'KBCA.BR', 'MELE.BR', 'ONTEX.BR', 'PROX.BR', 'SHUR.BR', 'SOLB.BR', 'TNET.BR', 'UCB.BR', 'VGP.BR', 'WDP.BR', 'XIOR.BR', 'ALK-B.CO', 'ALMB.CO', 'AMBU-B.CO', 'MAERSK-B.CO', 'BAVA.CO', 'BIOPOR.CO', 'BOOZT-DKK.CO', 'AOJ-B.CO', 'CARL-B.CO', 'CBRAIN.CO', 'CHEMM.CO', 'COLO-B.CO', 'COLUM.CO', 'DNORD.CO', 'DANSKE.CO', 'DFDS.CO', 'FLS.CO', 'GMAB.CO', 'GN.CO', 'GREENH.CO', 'HLUN-A.CO', 'HLUN-B.CO', 'HH.CO', 'ISS.CO', 'JYSK.CO', 'MATAS.CO', 'NETC.CO', 'NKT.CO', 'NNIT.CO', 'NDA-DK.CO', 'NOVO-B.CO', 'ORSTED.CO', 'PNDORA.CO', 'RILBA.CO', 'ROCK-B.CO', 'RBREW.CO', 'RTX.CO', 'SHAPE.CO', 'SKJE.CO', 'SPNO.CO', 'SYDB.CO', 'TRMD-A.CO', 'TRYG.CO', 'VWS.CO', 'VJBA.CO', 'DEMANT.CO', 'ZEAL.CO', 'ANA.MC', 'ACX.MC', 'AENA.MC', 'AMP.MC', 'APPS.MC', 'AI.MC', 'A3M.MC', 'ADX.MC', 'BBVA.MC', 'SAN.MC', 'BKY.MC', 'BST.MC', 'CABK.MC', 'CLNX.MC', 'LOG.MC', 'CIE.MC', 'ANE.MC', 'EDR.MC', 'ENC.MC', 'GEST.MC', 'DOM.MC', 'GCO.MC', 'IBE.MC', 'ITX.MC', 'COL.MC', 'IAG.MC', 'ROVI.MC', 'MRL.MC', 'MTB.MC', 'NTGY.MC', 'NXT.MC', 'OHLA.MC', 'PHM.MC', 'SPH.MC', 'CASH.MC', 'SCYR.MC', 'TEF.MC', 'UBS.MC', 'VID.MC', 'BFF.MI', 'BGN.MI', 'IF.MI', 'BMPS.MI', 'BPE.MI', 'BPSO.MI', 'PRO.MI', 'BST.MI', 'BAMI.MI', 'BE.MI', 'BNP.MI', 'BC.MI', 'BZU.MI', 'CPR.MI', 'CRL.MI', 'CEM.MI', 'CNHI.MI', 'CE.MI', 'DIS.MI', 'DAN.MI', 'DAL.MI', 'DLG.MI', 'DEA.MI', 'DBK.MI', 'DOV.MI', 'ELN.MI', 'ENAV.MI', 'ENI.MI', 'EPR.MI', 'EXAI.MI', 'FNX.MI', 'RACE.MI', 'FILA.MI', 'FCT.MI', 'FBK.MI', 'US.MI', 'FCM.MI', 'FUL.MI', 'GAMB.MI', 'GE.MI', 'GEO.MI', 'GO.MI', 'GVS.MI', 'HER.MI', 'IE.MI', 'ILTY.MI', 'IGD.MI', 'DNR.MI', 'IP.MI', 'IRE.MI', 'ITW.MI', 'IIG.MI', 'IVG.MI', 'JUVE.MI', 'LR.MI', 'LDO.MI', 'MT.MI', 'MARR.MI', 'MB.MI', 'MFEA.MI', 'MFEB.MI', 'MONC.MI', 'NSP.MI', 'NWL.MI', 'OJM.MI', 'PRL.MI', 'PIRC.MI', 'PRM.MI', 'PRY.MI', 'RWAY.MI', 'RST.MI', 'SFL.MI', 'SPM.MI', 'SCF.MI', 'SFER.MI', 'SL.MI', 'IOT.MI', 'SERI.MI', 'SRG.MI', 'SO.MI', 'STLAM.MI', 'STM.MI', 'TGYM.MI', 'TPRO.MI', 'TIT.MI', 'TITR.MI', 'TEF.MI', 'TEN.MI', 'TRN.MI', 'TKA.MI', 'TNXT.MI', 'TOD.MI', 'TXT.MI', 'UCG.MI', 'DAPP.MI', 'VNT.MI', 'WBD.MI', 'ZV.MI', 'A2A.MI', 'AED.MI', 'ALA.MI', 'AMZN.MI', 'AMP.MI', 'ANIM.MI', 'AV.MI', 'ARIS.MI', 'ASC.MI', 'G.MI', 'AGL.MI', 'AVIO.MI', '2020.OL', 'ABG.OL', 'AFG.OL', 'AMSC.OL', 'ABT.OL', 'ARCH.OL', 'ARR.OL', 'ASA.OL', 'BCS.OL', 'BORR.OL', 'DNB.OL', 'ENTRA.OL', 'EQNR.OL', 'EPR.OL', 'FLNG.OL', 'FRO.OL', 'GOGL.OL', 'GSF.OL', 'HEX.OL', 'JIN.OL', 'NAPA.OL', 'NEXT.OL', 'NAS.OL', 'NRC.OL', 'PEN.OL', 'PHO.OL', 'SAGA.OL', 'SATS.OL', 'SDRL.OL', 'SBO.OL', 'SPOL.OL', 'STB.OL', 'STRO.OL', 'TEL.OL', 'TGS.OL', 'VOW.OL', 'VGM.OL', 'WEST.OL', 'ZAL.OL', 'AALB.AS', 'ABN.AS', 'AXS.AS', 'ADYEN.AS', 'AD.AS', 'AKZA.AS', 'ALFEN.AS', 'ALLFG.AS', 'AMG.AS', 'APAM.AS', 'ARCAD.AS', 'MT.AS', 'ASM.AS', 'ASML.AS', 'ASRNL.AS', 'AVTX.AS', 'BAMNB.AS', 'BFIT.AS', 'CCEP.AS', 'CTPNV.AS', 'DSFIR.AS', 'EXO.AS', 'FAST.AS', 'FUR.AS', 'GLPG.AS', 'HEIJM.AS', 'HEIA.AS', 'HEIO.AS', 'IMCD.AS', 'INGA.AS', 'INPST.AS', 'JDEP.AS', 'TKWY.AS', 'KPN.AS', 'MAREL.AS', 'NN.AS', 'PSH.AS', 'PHARM.AS', 'PHIA.AS', 'PNL.AS', 'PRX.AS', 'REN.AS', 'RWI.AS', 'SBMO.AS', 'SHELL.AS', 'LIGHT.AS', 'TWEKA.AS', 'TOM2.AS', 'URW.AS', 'UNA.AS', 'UMG.AS', 'VLK.AS', 'VPK.AS', 'WHA.AS', 'WKL.AS', 'AAK.ST', 'ABB.ST', 'ACAD.ST', 'ATIC.ST', 'ALIF-B.ST', 'ANOD-B.ST', 'ADDT-B.ST', 'ALFA.ST', 'ALIG.ST', 'ATORX.ST', 'AMBEA.ST', 'AQ.ST', 'ARISE.ST', 'ARJO-B.ST', 'ASSA-B.ST', 'AZN.ST', 'ATCO-A.ST', 'ATCO-B.ST', 'ATRLJ-B.ST', 'ATT.ST', 'AXFO.ST', 'B3.ST', 'BALCO.ST', 'BEGR.ST', 'BEIA-B.ST', 'BEIJ-B.ST', 'BETS-B.ST', 'BETCO.ST', 'BILI-A.ST', 'BILL.ST', 'BIOA-B.ST', 'BIOG-B.ST', 'BONAV-B.ST', 'BONEX.ST', 'BOOZT.ST', 'BUFAB.ST', 'BULTEN.ST', 'BURE.ST', 'BHG.ST', 'CRAD-B.ST', 'CALTX.ST', 'CANTA.ST', 'CAST.ST', 'CATE.ST', 'CLAS-B.ST', 'CLA-B.ST', 'COLL.ST', 'COIC.ST', 'COOR.ST', 'CORE-PREF.ST', 'CRED-A.ST', 'DEDI.ST', 'DIOS.ST', 'DOM.ST', 'DORO.ST', 'DUNI.ST', 'ELUX-B.ST', 'EPRO-B.ST', 'EKTA-B.ST', 'ENQ.ST', 'EOLU-B.ST', 'EPI-A.ST', 'EPI-B.ST', 'EQT.ST', 'ESSITY-B.ST', 'EVO.ST', 'FABG.ST', 'BALD-B.ST', 'FPAR-A.ST', 'FING-B.ST', 'G5EN.ST', 'GIGSEK.ST', 'GETI-B.ST', 'GRNG.ST', 'HNSA.ST', 'HANZA.ST', 'HM-B.ST', 'HEXA-B.ST', 'HTRO.ST', 'HPOL-B.ST', 'HMS.ST', 'HOFI.ST', 'HOLM-B.ST', 'HUFV-A.ST', 'HUM.ST', 'HUSQ-B.ST', 'IAR-B.ST', 'IMMNOV.ST', 'INDU-C.ST', 'INDU-A.ST', 'INSTAL.ST', 'IPCO.ST', 'INTRUM.ST', 'LATO-B.ST', 'INVE-A.ST', 'INVE-B.ST', 'IVSO.ST', 'INWI.ST', 'JM.ST', 'KAR.ST', 'KIND-SDB.ST', 'KINV-B.ST', 'LAGR-B.ST', 'LIFCO-B.ST', 'LIAB.ST', 'LOOMIS.ST', 'LUND-B.ST', 'LUG.ST', 'LUMI.ST', 'MCOV-B.ST', 'MEKO.ST', 'TIGO-SDB.ST', 'MIPS.ST', 'MTG-B.ST', 'MMGR-B.ST', 'MTRS.ST', 'MYCR.ST', 'NCC-B.ST', 'NETI-B.ST', 'NEWA-B.ST', 'NGS.ST', 'NIBE-B.ST', 'NOBI.ST', 'NOLA-B.ST', 'NDA-SE.ST', 'NP3.ST', 'OEM-B.ST', 'PNDX-B.ST', 'PEAB-B.ST', 'PFE.ST', 'PLAZ-B.ST', 'PREV-B.ST', 'PRIC-B.ST', 'QLINEA.ST', 'RATO-B.ST', 'RAY-B.ST', 'REJL-B.ST', 'RESURS.ST', 'SAAB-B.ST', 'SAGA-B.ST', 'SAGA-D.ST', 'SBB-B.ST', 'SAND.ST', 'SCST.ST', 'SHOT.ST', 'SECT-B.ST', 'SECU-B.ST', 'SINT.ST', 'SEB-C.ST', 'SEB-A.ST', 'SKA-B.ST', 'SKF-B.ST', 'SKIS-B.ST', 'SSAB-B.ST', 'SSAB-A.ST', 'STAR-B.ST', 'STE-R.ST', 'SCA-B.ST', 'SHB-A.ST', 'SHB-B.ST', 'SVOL-B.ST', 'SWEC-B.ST', 'SWED-A.ST', 'SOBI.ST', 'SYSR.ST', 'TEL2-B.ST', 'ERIC-B.ST', 'TELIA.ST', 'TETY.ST', 'THULE.ST', 'TOBII.ST', 'TREL-B.ST', 'TROAX.ST', 'VIT-B.ST', 'VITR.ST', 'VOLO.ST', 'VOLV-A.ST', 'VOLV-B.ST', 'VNV.ST', 'WALL-B.ST', 'WIHL.ST', 'XBRANE.ST', 'XVIVO.ST', 'AB.PA', 'ADP.PA', 'AI.PA', 'AIR.PA', 'ALD.PA', 'ALO.PA', 'AMUN.PA', 'APAM.PA', 'MT.PA', 'AKE.PA', 'ATO.PA', 'AUB.PA', 'AVT.PA', 'CS.PA', 'BEN.PA', 'BB.PA', 'BIG.PA', 'BNP.PA', 'BVI.PA', 'CAP.PA', 'CO.PA', 'CRI.PA', 'CLARI.PA', 'COFA.PA', 'ACA.PA', 'BN.PA', 'AM.PA', 'EDEN.PA', 'ELIOR.PA', 'ELIS.PA', 'ENGI.PA', 'ALESK.PA', 'EL.PA', 'ES.PA', 'RF.PA', 'ERF.PA', 'FRVIA.PA', 'GTT.PA', 'RMS.PA', 'NK.PA', 'IPH.PA', 'IPN.PA', 'IPS.PA', 'DEC.PA', 'KOF.PA', 'KER.PA', 'LI.PA', 'OR.PA', 'FDJ.PA', 'LR.PA', 'MC.PA', 'MEDCL.PA', 'MERY.PA', 'ML.PA', 'NANO.PA', 'NEOEN.PA', 'NXI.PA', 'NRG.PA', 'ORA.PA', 'OSE.PA', 'OVH.PA', 'VAC.PA', 'POM.PA', 'PUB.PA', 'RCO.PA', 'RNO.PA', 'SAN.PA', 'SLB.PA', 'SU.PA', 'SCR.PA', 'SESG.PA', 'GLE.PA', 'SW.PA', 'SOI.PA', 'S30.PA', 'SPIE.PA', 'STLAP.PA', 'STMPA.PA', 'TE.PA', 'TEP.PA', 'HO.PA', 'TKO.PA', 'TTE.PA', 'TRI.PA', 'URW.PA', 'FR.PA', 'VK.PA', 'VLA.PA', 'VIE.PA', 'VRLA.PA', 'DG.PA', 'VIV.PA', 'VLTSA.PA', 'MF.PA', 'WLN.PA', 'XFAB.PA']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = '../db/tickers_total_daily_price_greater_than_e6.csv'\n",
    "\n",
    "def csv_to_list(file_path):\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        column_list = [row[0] for row in reader]\n",
    "\n",
    "    return column_list\n",
    "\n",
    "result_list = csv_to_list(file_path)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pkl file to csv or xls file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = 'ohlcv_ntickers_1254_2000-08-01_to_2023-12-23'\n",
    "folder_path = '../db/'\n",
    "\n",
    "data = pd.read_pickle(f'{folder_path}{file_name}.pkl')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reset MultiIndex columns to a single level\n",
    "# df.columns = df.columns.droplevel(0)\n",
    "\n",
    "# df.to_excel(f'{folder_path}{file_name}_numbers.xlsx', engine='openpyxl', float_format=\"%.5f\")\n",
    "df.to_excel(f'{folder_path}{file_name}_numbers.xlsx', float_format=\"%.5f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
