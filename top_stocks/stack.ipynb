{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76440\n"
     ]
    }
   ],
   "source": [
    "import utils.helper_functions as hf\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "db_file_path = 'db/ohlcv_ntickers_1254_2000-08-01_to_2023-12-23.pkl'\n",
    "\n",
    "export_folder_path = './outputs/'\n",
    "export_name = 'results'\n",
    "\n",
    "fee = 0.002\n",
    "\n",
    "# n_days_past_range = [1,2]\n",
    "# n_days_future_range = [2]\n",
    "# filter_lower_limit_range = [-100]\n",
    "# filter_width_range = [50]\n",
    "# loss_limit_range = [-0.5]\n",
    "\n",
    "n_days_past_range = [1,2,3,4,5]\n",
    "n_days_future_range = [1,2,3,4,5,10,15,20,25,30,35,40,45,50]\n",
    "filter_lower_limit_range = [-10000,-1000,-500,-200,-150,-140,-130,-120,-110,-100,-90,-80,-70]\n",
    "filter_width_range = [10,20,30,40,50,60,70,80,90,100,140,440,940,9940]\n",
    "loss_limit_range = [-1000, -100, -50, -20, -10, -5]\n",
    "\n",
    "num_combinations = hf.get_num_combinations([n_days_past_range, n_days_future_range, filter_lower_limit_range, filter_width_range, loss_limit_range])\n",
    "# num_combinations = len(n_days_past_range) * len(n_days_future_range) * len(filter_lower_limit_range) * len(filter_width_range) * len(loss_limit_range)\n",
    "# print(num_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_top_column_name(df):\n",
    "#     return df.droplevel(0, axis=1)\n",
    "\n",
    "data = pd.read_pickle(db_file_path)\n",
    "\n",
    "# open_data = remove_top_column_name(data[[\"Open\"]])\n",
    "# low_data = remove_top_column_name(data [[\"Low\"]])\n",
    "\n",
    "open_data = hf.remove_top_column_name(data[[\"Open\"]])\n",
    "low_data = hf.remove_top_column_name(data [[\"Low\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_floor_mask(open_df, low_df, loss_limit, n_days_future):\n",
    "#     indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=n_days_future) # between current day and day before n_days_future\n",
    "#     future_min_values = low_df.rolling(window=indexer).min()\n",
    "#     loss_threshold = open_df * (1 + (loss_limit / 100))\n",
    "\n",
    "#     floor_mask = future_min_values < loss_threshold\n",
    "    \n",
    "#     return floor_mask\n",
    "\n",
    "def create_floored_future_var(open_df, low_df, loss_limit, n_days_future, future_var):\n",
    "    # floor_mask = create_floor_mask(open_df, low_df, loss_limit, n_days_future)\n",
    "    floor_mask = hf.create_floor_mask(open_df, low_df, loss_limit, n_days_future)\n",
    "    floor_mask = floor_mask.stack(dropna=False)\n",
    "\n",
    "    floored_future_var = future_var.copy()\n",
    "    floored_future_var[floor_mask] = loss_limit\n",
    "\n",
    "    return floored_future_var\n",
    "\n",
    "def create_taxed_future_var(df, fee):\n",
    "    # taxed_profit = (1 + (df / 100)) * (1 - fee) / (1 + fee)\n",
    "    taxed_profit = hf.apply_fee(1 + (df / 100), fee)\n",
    "    taxed_var = (taxed_profit - 1) * 100\n",
    "    \n",
    "    return taxed_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_year_column(df):\n",
    "#     return df.index.get_level_values(0).astype(str).str[:4]\n",
    "\n",
    "# def concat_dfs(dfs, column_names):    \n",
    "#     df = pd.concat(dfs, axis=1, keys=column_names)\n",
    "#     df = df.dropna()\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def add_10_last_years_stats(df):\n",
    "    df = df.sort_index(axis=1)\n",
    "\n",
    "    medians_10_last_years = df.loc[:, 'median_2013':'median_2023']\n",
    "    means_10_last_years = df.loc[:, 'mean_2013':'mean_2023']\n",
    "    counts_10_last_years = df.loc[:, 'count_2013':'count_2023']\n",
    "\n",
    "    df['median_median_10_last_years'] = medians_10_last_years.median(axis=1)\n",
    "    df['mean_median_10_last_years'] = medians_10_last_years.mean(axis=1)\n",
    "    df['min_median_10_last_years'] = medians_10_last_years.min(axis=1)\n",
    "\n",
    "    df['median_mean_10_last_years'] = means_10_last_years.median(axis=1)\n",
    "    df['mean_mean_10_last_years'] = means_10_last_years.mean(axis=1)\n",
    "    df['min_mean_10_last_years'] = means_10_last_years.min(axis=1)\n",
    "\n",
    "    \n",
    "    df['median_count_10_last_years'] = counts_10_last_years.median(axis=1)\n",
    "    df['mean_count_10_last_years'] = counts_10_last_years.mean(axis=1)\n",
    "    df['min_count_10_last_years'] = counts_10_last_years.min(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def replace_by_zeros(df, col_name_beginning):\n",
    "    columns = [col for col in df.columns if col.startswith(col_name_beginning)]\n",
    "    df[columns] = df[columns].fillna(0).replace('', 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_var(df, start_day, end_day):\n",
    "    var = (df.shift(-end_day) - df.shift(-start_day)) / df.shift(-start_day) * 100\n",
    "    \n",
    "    return var.stack(dropna=False)\n",
    "\n",
    "# def calculate_filtered_var(df, col, lower_limit, width):\n",
    "#     return df[(df[col] >= lower_limit) & (df[col] <= lower_limit + width)]\n",
    "\n",
    "# def calculate_success_rate(df):\n",
    "#     positive_values_count = (df > 0).sum()\n",
    "#     values_count = len(df)\n",
    "\n",
    "#     return (positive_values_count / values_count) if values_count != 0 else float('nan')\n",
    "\n",
    "def calculate_overall_results(df_col):\n",
    "    return pd.DataFrame({\n",
    "        'n_results': [len(df_col)],\n",
    "        'median': [df_col.median()],\n",
    "        'mean': [df_col.mean()],\n",
    "        #'success_rate': [calculate_success_rate(df_col),\n",
    "        'success_rate': [hf.calculate_positive_rate(df_col)]\n",
    "    })\n",
    "\n",
    "def calculate_yearly_results(df, column):\n",
    "    pivot_table = pd.pivot_table(\n",
    "        df,\n",
    "        values=[column],\n",
    "        index=['year'],\n",
    "        aggfunc={column: ['median', 'mean', 'min', 'max', 'count']})\n",
    "\n",
    "    pivot_table = pivot_table.unstack().to_frame().sort_index(level=1).T\n",
    "    pivot_table.columns = ['_'.join(col) for col in pivot_table.columns]\n",
    "    pivot_table.columns = pivot_table.columns.str.replace(f'{column}_', '')\n",
    "    pivot_table = pivot_table.reindex(sorted(pivot_table.columns), axis=1)\n",
    "\n",
    "    return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_results(df, export_name):\n",
    "#     def get_date():\n",
    "#         return datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "#     date = get_date()\n",
    "\n",
    "#     export_file_path = f'{export_folder_path}{export_name}_{date}'\n",
    "\n",
    "#     print('Saving files...')\n",
    "    \n",
    "#     df.to_csv(f'{export_file_path}.csv')\n",
    "#     df.to_excel(f'{export_file_path}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step: 76440/76440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/b84w4ts97b728gp2r8cchfgw0000gn/T/ipykernel_42987/1914160273.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['mean_count_10_last_years'] = counts_10_last_years.mean(axis=1)\n",
      "/var/folders/1x/b84w4ts97b728gp2r8cchfgw0000gn/T/ipykernel_42987/1914160273.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['min_count_10_last_years'] = counts_10_last_years.min(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "for n_days_past, n_days_future in product(n_days_past_range, n_days_future_range):\n",
    "    past_var = calculate_var(df=open_data, start_day=-n_days_past, end_day=0)\n",
    "    future_var = calculate_var(df=open_data, start_day=0, end_day=n_days_future)\n",
    "\n",
    "    for loss_limit in loss_limit_range:\n",
    "        floored_future_var = create_floored_future_var(open_data, low_data, loss_limit, n_days_future, future_var)\n",
    "        taxed_floored_future_var = create_taxed_future_var(floored_future_var, fee)\n",
    "        \n",
    "        # var = concat_dfs(\n",
    "        #     dfs=[past_var, future_var, taxed_floored_future_var],\n",
    "        #     column_names=['past_var', 'future_var', 'taxed_floored_future_var'])\n",
    "        var = hf.concat_dfs(df_list=[past_var, future_var, taxed_floored_future_var],\n",
    "            column_list=['past_var', 'future_var', 'taxed_floored_future_var'])\n",
    "\n",
    "        # var['year'] = get_year_column(var)\n",
    "        var['year'] = hf.get_last_characters_from_index(var, 4)\n",
    "\n",
    "        for filter_lower_limit, filter_width in product(filter_lower_limit_range, filter_width_range):\n",
    "            # var_filtered = calculate_filtered_var(\n",
    "            #     df=var, col='past_var',\n",
    "            #     lower_limit=filter_lower_limit, width=filter_width)\n",
    "            var_filtered = hf.filter_by_lower_and_upper_limits(df=var, column=past_var,\n",
    "                lower_limit=filter_lower_limit, upper_limit=filter_lower_limit+filter_width)\n",
    "\n",
    "            params = pd.DataFrame({'n_days_past': [n_days_past], 'n_days_future': [n_days_future],\n",
    "                      'filter_lower_limit': [filter_lower_limit], 'filter_width': [filter_width],\n",
    "                      'loss_limit': [loss_limit]})\n",
    "            overall_results = calculate_overall_results(df_col=var_filtered['taxed_floored_future_var'])\n",
    "            yearly_results = calculate_yearly_results(df=var_filtered, column='taxed_floored_future_var')\n",
    "            new_results = pd.concat([params, overall_results, yearly_results], axis='columns')\n",
    "\n",
    "            results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "            i += 1\n",
    "            # print(f'\\r step: {i}/{num_combinations}', end='')\n",
    "            hf.print_progress(i, num_combinations)\n",
    "\n",
    "results = replace_by_zeros(df=results, col_name_beginning='count')\n",
    "results = add_10_last_years_stats(results)\n",
    "results.sort_values('median_median_10_last_years', ascending=False, inplace=True)\n",
    "\n",
    "# save_results(results, export_name)\n",
    "hf.save_df_as_csv(df=results, folder_path=export_folder_path, file_name=export_name)\n",
    "hf.save_df_as_xlsx(df=results, folder_path=export_folder_path, file_name=export_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
