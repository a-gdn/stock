{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tracemalloc\n",
    "\n",
    "# tracemalloc.start()\n",
    "# snapshot1 = tracemalloc.take_snapshot()\n",
    "\n",
    "import config as cfg\n",
    "from utils import helper_functions as hf\n",
    "from utils import inputs\n",
    "from utils import outputs\n",
    "from utils import tf_classifier_model\n",
    "from utils import evaluate as eval\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_FAIL, STATUS_OK, Trials\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1' # disable file validation in the debugger\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #0: All logs (default setting), 1: Filter out INFO logs, up to 3\n",
    "pd.options.mode.copy_on_write = True # avoid making unnecessary copies of DataFrames or Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations = cfg.hyperopt_n_iterations if cfg.use_hyperopt else hf.get_num_combinations(cfg.param_grid)\n",
    "\n",
    "print(num_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_combination(hyperparams):\n",
    "    return hyperparams['target_future_days'] != 0 or (hyperparams['buying_time'] == 'Open' and hyperparams['selling_time'] == 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(cfg.db_path)\n",
    "df = hf.get_rows_after_date(df, cfg.start_date)\n",
    "df = hf.fillnavalues(df)\n",
    "\n",
    "def get_single_level_df(df, ohlcv):\n",
    "    new_df = df[[ohlcv]]\n",
    "    new_df = hf.remove_top_column_name(new_df)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def get_ohlcv_dfs(df):\n",
    "    df_open = get_single_level_df(df, 'Open')\n",
    "    df_high = get_single_level_df(df, 'High')\n",
    "    df_low = get_single_level_df(df, 'Low')\n",
    "    df_close = get_single_level_df(df, 'Close')\n",
    "    df_volume = get_single_level_df(df, 'Volume')\n",
    "    \n",
    "    return {'df_open': df_open, 'df_high': df_high, 'df_low': df_low,\n",
    "            'df_close': df_close, 'df_volume': df_volume}\n",
    "\n",
    "num_tickers = hf.get_num_tickers(get_single_level_df(df, 'Open'))\n",
    "print(f'number of tickers: {num_tickers}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_data(hyperparams):\n",
    "    df_buy = get_single_level_df(df, hyperparams['buying_time'])\n",
    "    df_sell = get_single_level_df(df, hyperparams['selling_time'])\n",
    "    dfs_ohlcv = get_ohlcv_dfs(df)\n",
    "\n",
    "    if os.path.exists(cfg.transformed_data_path) and cfg.use_saved_transformed_data:\n",
    "        df_data = pd.read_pickle(cfg.transformed_data_path)\n",
    "        # print(f'using existing {cfg.transformed_data_path}')\n",
    "    else:\n",
    "        # print(f'need to create {cfg.transformed_data_path}')\n",
    "        df_data = inputs.get_inputs(df_buy, dfs_ohlcv, hyperparams['buying_time'])\n",
    "        \n",
    "        df_data.to_pickle(cfg.transformed_data_path)\n",
    "        # print(f'saved new {cfg.transformed_data_path}')\n",
    "\n",
    "    df_data = outputs.add_outputs(df_data, df_buy, df_sell, dfs_ohlcv, num_tickers, cfg.output_binary_name, cfg.fee, **hyperparams)\n",
    "\n",
    "    df_data = df_data.dropna()\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path):\n",
    "    \"\"\"Load results from an Excel file if it exists.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading results from {path}\")\n",
    "        return pd.read_excel(path).to_dict(orient='records') # Return a list of dictionaries\n",
    "    return [] # Return an empty list if no file exists\n",
    "\n",
    "def load_trials(path):\n",
    "    \"\"\"Load the Trials object from a file if it exists.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading trials from {path}\")\n",
    "        return pd.read_pickle(path)\n",
    "    return Trials() # Return a new Trials object if no file exists\n",
    "\n",
    "def save_results(results, trials, results_path, trials_path):\n",
    "    \"\"\"Save results and trials.\"\"\"\n",
    "    # Save results\n",
    "    pd.DataFrame(results).to_excel(results_path, index=False)   \n",
    "\n",
    "    # Save trials if Hyperopt is used\n",
    "    if trials is not None:\n",
    "        pd.to_pickle(trials, trials_path)\n",
    "\n",
    "def save_results_if_needed(results, trials, iteration, total_iterations, results_path, trials_path):\n",
    "    \"\"\"Save results periodically or at the end of iterations. Clear the print output.\"\"\"\n",
    "    if iteration % cfg.save_every_n_iterations == 0 or iteration == total_iterations:\n",
    "        save_results(results, trials, results_path, trials_path)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "def print_results(results):\n",
    "    \"\"\"Display the top results in a sorted DataFrame.\"\"\"\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by='performance_score', ascending=False)\n",
    "    print(df_results.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def get_model_result(hyperparams):\n",
    "    \"\"\"Run the model with the given hyperparameters and return the results.\"\"\"\n",
    "    print(f\"Evaluating hyperparameters: {hyperparams}\")\n",
    "\n",
    "    df_data = get_df_data(hyperparams)\n",
    "    test_train_data, model = tf_classifier_model.load_tf_model(df_data, hyperparams)\n",
    "    performance_metrics = eval.evaluate_model(df_data, model, test_train_data, num_tickers, num_combinations, hyperparams)\n",
    "\n",
    "    result = {**performance_metrics, **hyperparams, 'epochs': cfg.epochs}\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def hyperopt_search(results):\n",
    "    \"\"\"Run Hyperopt-based optimization.\"\"\"\n",
    "    def objective(hyperparams):   \n",
    "        try:\n",
    "            if not is_valid_combination(hyperparams):\n",
    "                print(\"Invalid hyperparameter combination.\")\n",
    "                return {'loss': float('inf'), 'status': STATUS_FAIL}\n",
    "            \n",
    "            result = get_model_result(hyperparams)\n",
    "            results.append(result)\n",
    "            save_results_if_needed(results, trials, len(trials), cfg.hyperopt_n_iterations, cfg.results_path, cfg.trials_path)\n",
    "\n",
    "            # Extract performance score from the result\n",
    "            performance = result.get('performance_score', None)\n",
    "            if performance is None:\n",
    "                print(\"Missing performance score in result.\")\n",
    "                return {'loss': float('inf'), 'status': STATUS_FAIL}\n",
    "\n",
    "            return {'loss': -performance, 'status': STATUS_OK}\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Skipping trial, error: {e}')\n",
    "            return {'status': STATUS_FAIL} # Hyperopt will ignore this trial\n",
    "    \n",
    "    trials = load_trials(cfg.trials_path)\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=cfg.search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=cfg.hyperopt_n_iterations,\n",
    "        trials=trials\n",
    "    )\n",
    "    print(f'Best parameters: {best}')\n",
    "    return trials\n",
    "\n",
    "def grid_search(results):\n",
    "    \"\"\"Run a manual grid search.\"\"\"\n",
    "    param_combinations = list(product(*cfg.param_grid.values()))\n",
    "\n",
    "    for i, params in enumerate(param_combinations, start=1):\n",
    "        hf.print_combination(i, num_combinations)\n",
    "        hyperparams = dict(zip(cfg.param_grid.keys(), params))\n",
    "\n",
    "        try:\n",
    "            if not is_valid_combination(hyperparams):\n",
    "                print(f\"Skipping invalid combination {i}/{num_combinations}: {hyperparams}\")\n",
    "                continue\n",
    "            \n",
    "            result = get_model_result(hyperparams)\n",
    "            results.append(result)\n",
    "            save_results_if_needed(results, None, i, num_combinations)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at combination {i}/{num_combinations}: {e}\")\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    results = load_results(cfg.results_path)\n",
    "\n",
    "    if cfg.use_hyperopt:\n",
    "        trials = hyperopt_search(results)\n",
    "    else:\n",
    "        grid_search(results)\n",
    "\n",
    "    save_results(results, trials if cfg.use_hyperopt else None, cfg.results_path, cfg.trials_path)\n",
    "    print_results(results)\n",
    "\n",
    "# snapshot2 = tracemalloc.take_snapshot()\n",
    "# top_stats = snapshot2.compare_to(snapshot1, 'lineno')\n",
    "\n",
    "# for stat in top_stats[:6]:\n",
    "#     print(stat)\n",
    "\n",
    "# tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffeinate_process = subprocess.Popen([\"caffeinate\", \"-dims\"])\n",
    "print(\"Caffeinate started...\")\n",
    "\n",
    "try:\n",
    "    main()\n",
    "finally:\n",
    "    caffeinate_process.terminate()\n",
    "    print(\"Caffeinate stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
