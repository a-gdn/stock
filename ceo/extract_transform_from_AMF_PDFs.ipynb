{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract specific text from PDF\n",
    "def extract_info_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    \n",
    "    # Define regex patterns for information extraction\n",
    "    name_pattern = r\"PERSONNE ETROITEMENT LIEE :(.*?)(?=,|$)\"\n",
    "    position_pattern = r\",(.*?)(?=NOTIFICATION|$)\"\n",
    "    company_name_pattern = r\"NOM :(.*?)(?=LEI|DETAIL|$)\" # LEI or DETAIL to stop\n",
    "    date_pattern = r\"DATE DE LA TRANSACTION :(.*?)(?=LIEU|$)\"\n",
    "    nature_pattern = r\"NATURE DE LA TRANSACTION :(.*?)(?=DESCRIPTION|$)\"\n",
    "    price_pattern = r\"PRIX :(.*?)(?=Euro|Dollar|Livre|Franc|$)\"\n",
    "    volume_pattern = r\"VOLUME :((?:(?!VOLUME :|TRANSACTION).)*)\\s*TRANSACTION\" # last occurence\n",
    "    date_notification_pattern = r\"DATE DE RECEPTION DE LA NOTIFICATION :(.*?)(?=COMMENTAIRES|$)\"\n",
    "\n",
    "    name = re.search(name_pattern, text, re.DOTALL)\n",
    "    position = re.search(position_pattern, text, re.DOTALL)\n",
    "    company_name = re.search(company_name_pattern, text, re.DOTALL)\n",
    "    date_transaction = re.search(date_pattern, text, re.DOTALL)\n",
    "    nature = re.search(nature_pattern, text, re.DOTALL)\n",
    "    price = re.search(price_pattern, text, re.DOTALL)\n",
    "    volume = re.search(volume_pattern, text, re.DOTALL)\n",
    "    date_notification = re.search(date_notification_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Extracted information\n",
    "    def convert_to_text(re_search_result):\n",
    "        return re_search_result.group(1).strip() if re_search_result else \"\"\n",
    "    \n",
    "    name_text = convert_to_text(name)\n",
    "    position_text = convert_to_text(position)\n",
    "    company_name_text = convert_to_text(company_name)\n",
    "    date_transaction_text = convert_to_text(date_transaction)\n",
    "    nature_text = convert_to_text(nature)\n",
    "    price_text = convert_to_text(price)\n",
    "    volume_text = convert_to_text(volume)\n",
    "    date_notification_text = convert_to_text(date_notification)\n",
    "\n",
    "    text_dict = {'name': name_text, 'position': position_text, 'company_name': company_name_text,\n",
    "                 'date_transaction': date_transaction_text, 'date_notification': date_notification_text,\n",
    "                 'nature': nature_text, 'price': price_text, 'volume': volume_text}\n",
    "    \n",
    "    return text_dict\n",
    "\n",
    "folder_path = \"./amf-pdfs/\"\n",
    "\n",
    "# Find all PDF files in the folder\n",
    "pdf_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "print(f'list of PDF files: {pdf_files}')\n",
    "total_files = len(pdf_files)\n",
    "print(f'number of PDF files: {total_files}')\n",
    "\n",
    "data = []\n",
    "\n",
    "# Extract information from each PDF and store it in the dataframe\n",
    "for i, file in enumerate(pdf_files, 1):\n",
    "    print(f'\\r {i}/{total_files}')\n",
    "    new_info_dict = extract_info_from_pdf(file)\n",
    "    data.append(new_info_dict)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import locale\n",
    "\n",
    "# Set the French locale for month names\n",
    "locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "df['date_transaction'] = pd.to_datetime(df['date_transaction'], format='%d %B %Y', errors='coerce')\n",
    "df['date_notification'] = pd.to_datetime(df['date_notification'], format='%d %B %Y', errors='coerce')\n",
    "\n",
    "# Reset the locale to the default setting\n",
    "locale.setlocale(locale.LC_TIME, '')\n",
    "\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Price and Volume are Float values\n",
    "df['price'] = df['price'].astype(str).str.replace(' ', '').astype(float)\n",
    "df['volume'] = df['volume'].astype(str).str.replace(' ', '').astype(float)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_names = df['company_name'].unique()\n",
    "\n",
    "# ticker_mapping = {}\n",
    "\n",
    "# for company_name in company_names:\n",
    "#     ticker_mapping[company_name] = '.PA'\n",
    "\n",
    "# ticker_mapping = dict(sorted(ticker_mapping.items()))\n",
    "\n",
    "# print(ticker_mapping)\n",
    "\n",
    "import ticker_mapping\n",
    "ticker_mapping = ticker_mapping.ticker_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = df['company_name'].unique()\n",
    "missing_keys = [company_name for company_name in company_names if company_name not in ticker_mapping]\n",
    "print(f'missing keys: {missing_keys}')\n",
    "\n",
    "df['ticker'] = df['company_name'].map(ticker_mapping)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "\n",
    "# Get current and future stock prices and variations\n",
    "def get_stock_prices(row):\n",
    "    try:\n",
    "        ticker = row['ticker']\n",
    "        start_day = row['date_transaction']\n",
    "        end_day = start_day + timedelta(days=90)\n",
    "        start_day = start_day.strftime('%Y-%m-%d')\n",
    "        end_day = end_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        stock = yf.Ticker(ticker)\n",
    "        stock_data = stock.history(start=start_day, end=end_day)\n",
    "        prices = stock_data['Open']\n",
    "        prices_dict = {\n",
    "            'stock_price_open_d0': prices.values[0],\n",
    "            'var_d1': prices.values[1] / prices.values[0],\n",
    "            'var_d3': prices.values[3] / prices.values[0],\n",
    "            'var_d5': prices.values[5] / prices.values[0],\n",
    "            'var_d10': prices.values[10] / prices.values[0],\n",
    "            'var_d20': prices.values[20] / prices.values[0],\n",
    "            'var_d30': prices.values[30] / prices.values[0],\n",
    "            'var_d60': prices.values[60] / prices.values[0]\n",
    "        }\n",
    "        return pd.Series(prices_dict)\n",
    "    except:\n",
    "        return {\n",
    "            'stock_price_open_d0': float('nan'),\n",
    "            'var_d1': float('nan'),\n",
    "            'var_d3': float('nan'),\n",
    "            'var_d5': float('nan'),\n",
    "            'var_d10': float('nan'),\n",
    "            'var_d20': float('nan'),\n",
    "            'var_d30': float('nan'),\n",
    "            'var_d60': float('nan')\n",
    "        }\n",
    "\n",
    "# Applying the function to new columns\n",
    "df = pd.concat([df, df.apply(get_stock_prices, axis=1)], axis=1)\n",
    "\n",
    "df.head(15)\n",
    "\n",
    "df.to_pickle('amf-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test if cession and acquisition future variation are going up or down\n",
    "amf_data = pd.read_pickle('amf-data.pkl')\n",
    "amf_df = pd.DataFrame(amf_data)\n",
    "\n",
    "amf_df = amf_df[(amf_df['date_transaction'] >= '2022-01-01') & (amf_df['date_transaction'] <= '2022-04-30')]\n",
    "\n",
    "amf_df = amf_df[amf_df['price'] != 0]\n",
    "\n",
    "amf_df = amf_df[amf_df['position'].isin([\n",
    "    'Président Directeur Général', 'PDG',\n",
    "    'Président-Directeur Général', 'président-directeur général',\n",
    "    'DIRECTEUR', 'Directeur Général', 'DIRIGEANT',\n",
    "    'Directeur général', 'P.D.-G.'])]\n",
    "\n",
    "print(f'data length: {len(amf_df)}')\n",
    "\n",
    "df_cession = amf_df[amf_df['nature'] == 'Cession']\n",
    "# df_acquisition = amf_df[amf_df['nature'] == 'Acquisition']\n",
    "df_acquisition = amf_df[amf_df['nature'] != 'Cession']\n",
    "\n",
    "var_means = {\n",
    "    'cession': {\n",
    "        'd1': df_cession['var_d1'].mean(),\n",
    "        'd3': df_cession['var_d3'].mean(),\n",
    "        'd5': df_cession['var_d5'].mean(),\n",
    "        'd10': df_cession['var_d10'].mean(),\n",
    "        'd20': df_cession['var_d20'].mean(),\n",
    "        'd30': df_cession['var_d30'].mean(),\n",
    "        'd60': df_cession['var_d60'].mean(),\n",
    "    },\n",
    "    'acquisition' : {\n",
    "        'd1': df_acquisition['var_d1'].mean(),\n",
    "        'd3': df_acquisition['var_d3'].mean(),\n",
    "        'd5': df_acquisition['var_d5'].mean(),\n",
    "        'd10': df_acquisition['var_d10'].mean(),\n",
    "        'd20': df_acquisition['var_d20'].mean(),\n",
    "        'd30': df_acquisition['var_d30'].mean(),\n",
    "        'd60': df_acquisition['var_d60'].mean(),\n",
    "    }\n",
    "}\n",
    "\n",
    "var_medians = {\n",
    "    'cession': {\n",
    "        'd1': df_cession['var_d1'].median(),\n",
    "        'd3': df_cession['var_d3'].median(),\n",
    "        'd5': df_cession['var_d5'].median(),\n",
    "        'd10': df_cession['var_d10'].median(),\n",
    "        'd20': df_cession['var_d20'].median(),\n",
    "        'd30': df_cession['var_d30'].median(),\n",
    "        'd60': df_cession['var_d60'].median()\n",
    "    },\n",
    "    'acquisition' : {\n",
    "        'd1': df_acquisition['var_d1'].median(),\n",
    "        'd3': df_acquisition['var_d3'].median(),\n",
    "        'd5': df_acquisition['var_d5'].median(),\n",
    "        'd10': df_acquisition['var_d10'].median(),\n",
    "        'd20': df_acquisition['var_d20'].median(),\n",
    "        'd30': df_acquisition['var_d30'].median(),\n",
    "        'd60': df_acquisition['var_d60'].median()\n",
    "    }\n",
    "}\n",
    "\n",
    "var_means = {key: {inner_key: round(inner_value, 2) for inner_key, inner_value in value.items()} for key, value in var_means.items()}\n",
    "var_medians = {key: {inner_key: round(inner_value, 2) for inner_key, inner_value in value.items()} for key, value in var_medians.items()}\n",
    "\n",
    "print(var_means)\n",
    "print(var_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test if cession and acquisition future variation are going up or down\n",
    "amf_data = pd.read_pickle('amf-data.pkl')\n",
    "amf_df = pd.DataFrame(amf_data)\n",
    "amf_df = amf_df.sort_values(by='var_d5', ascending=False)\n",
    "\n",
    "pivot_table = pd.pivot_table(amf_df, values=['var_d1', 'var_d3', 'var_d5', 'var_d10', 'var_d20', 'var_d30', 'company_name'],\n",
    "                       index=['position', 'nature'], aggfunc={'var_d1': 'median',\n",
    "                                                    'var_d3': 'median',\n",
    "                                                    'var_d5': ['median', 'count'],\n",
    "                                                    'var_d10': 'median',\n",
    "                                                    'var_d20': 'median',\n",
    "                                                    'var_d30': 'median',\n",
    "                                                    'company_name': 'nunique'})\n",
    "pivot_table = pivot_table.sort_values(by=('var_d3', 'median'), ascending=False)\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "# amf_df.head(200)\n",
    "pivot_table.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table2 = pd.pivot_table(amf_df, values=['var_d1', 'var_d3', 'var_d5', 'var_d10', 'var_d20', 'var_d30'],\n",
    "                       index=['company_name', 'nature'], aggfunc={'var_d1': 'median',\n",
    "                                                    'var_d3': 'median',\n",
    "                                                    'var_d5': ['median', 'count'],\n",
    "                                                    'var_d10': 'median',\n",
    "                                                    'var_d20': 'median',\n",
    "                                                    'var_d30': 'median'})\n",
    "pivot_table2 = pivot_table2.sort_values(by=('var_d5', 'median'), ascending=False)\n",
    "\n",
    "pivot_table2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table3 = pd.pivot_table(amf_df, values=['var_d1', 'var_d3', 'var_d5', 'var_d10', 'var_d20', 'var_d30'],\n",
    "                       index=['name', 'company_name', 'nature'], aggfunc={'var_d1': 'median',\n",
    "                                                    'var_d3': 'median',\n",
    "                                                    'var_d5': ['median', 'count'],\n",
    "                                                    'var_d10': 'median',\n",
    "                                                    'var_d20': 'median',\n",
    "                                                    'var_d30': 'median'})\n",
    "pivot_table3 = pivot_table3.sort_values(by=('var_d5', 'median'), ascending=False)\n",
    "\n",
    "pivot_table3.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df = amf_df[amf_df['company_name'] == 'AMA CORPORATION PLC']\n",
    "selection_df.sort_values(by='var_d3', ascending=False)\n",
    "selection_df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
