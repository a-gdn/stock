sort out issue where some value might be sold below the limit loss threshold (occurs around 4 times in 10 years)

plot a graph nth_position_hold_days vs nth_postion_watched_days

Write a non-supervised self-learning code that:
- downloads from Yahoo Finance, from 2000-08-01 to 2022-12-31, this tickers list:
 ["AB.PA","A2A.MI","ABCA.PA","ABNX.PA","ABVX.PA","AC.PA","ADP.PA","AIR.PA"] 
- has a initial wallet of 50000 euros
- at each step:
    - observes these states:
        - percentage of stock value increase of the ticker list over the last W days (W comprised between 1 and 250)
        - position of the percentage of stock value increase of each ticker compared to the other tickers
        - the average percentage of stock value increase
        - the median percentage of stock value increase
    - possible actions :
        - buy any stock at Close in the tickers list:
            - with a possible option for stop loss ratio SL (SL comprised between 0 and 1)
            - with a possible option for take profit ratio TP (TP comprised between 1 and 10)
        - sell for any of the bought stock when:
            - reaching the stop loss 
            - reaching the stop win
            - after H days (H comprised between 1 and 400)
        - each action has a 0.6% fee
        - each action modifies the wallet value
- target: Maximize the wallet value. Find the best set of values for W, SL, TP and H

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import random

# Define the tickers list and date range
tickers = ["AB.PA", "A2A.MI", "ABCA.PA", "ABNX.PA", "ABVX.PA", "AC.PA", "ADP.PA", "AIR.PA"]
start_date = "2000-08-01"
end_date = "2022-12-31"

# Set initial wallet value
initial_wallet = 50000

# Define hyperparameters
learning_rate = 0.1
discount_factor = 0.99
exploration_rate = 0.2
num_episodes = 1000

# Define the state space parameters
W = 30  # Number of days for calculating percentage increase
num_tickers = len(tickers)
state_dim = num_tickers + 3  # Number of state features: num_tickers + average + median

# Define the action space parameters
stop_loss_ratios = [0.05, 0.1, 0.15]
take_profit_ratios = [1.5, 2.0, 2.5]
H_values = [10, 20, 30]

# Initialize the Q-table
q_table = np.zeros((state_dim, len(stop_loss_ratios), len(take_profit_ratios), len(H_values)))

# Retrieve stock data from Yahoo Finance
def get_stock_data(ticker):
    df = pd.read_csv(f"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_date}&period2={end_date}&interval=1d&events=history")
    df["Date"] = pd.to_datetime(df["Date"])
    df.set_index("Date", inplace=True)
    return df

# Calculate the percentage increase for a given window size
def calculate_percentage_increase(data, window):
    shifted_data = data.shift(window)
    percentage_increase = ((data - shifted_data) / shifted_data) * 100
    return percentage_increase

# Preprocess the data and generate states
def generate_states(data):
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data)
    states = []
    for i in range(W, len(data)):
        window_data = data_scaled[i-W:i]
        avg = np.mean(window_data)
        median = np.median(window_data)
        ticker_positions = np.argsort(window_data)
        state = np.concatenate((ticker_positions, [avg], [median]))
        states.append(state)
    return states

# Perform an action (buy/sell) and return the reward
def perform_action(action, wallet, stock_prices, stock_holding, stop_loss, take_profit, H):
    if action < num_tickers:
        # Buy action
        ticker_index = action
        stock_price = stock_prices[ticker_index]
        num_shares = int(wallet / stock_price)
        wallet -= (stock_price * num_shares) * 1.006  # Deduct fee
        stock_holding[ticker_index] += num_shares
        stop_loss[ticker_index] = stock_price * (1 - stop_loss_ratios[stop_loss_ratio_index])
        take_profit[ticker_index] = stock_price * take_profit_ratios[take_profit_ratio_index]
        return 0  # No immediate reward after buying
    else